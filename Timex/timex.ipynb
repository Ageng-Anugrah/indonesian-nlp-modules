{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change to available GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn_crfsuite import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    BertForTokenClassification,\n",
    "    BertTokenizerFast,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from utils.bert_utils import dataset\n",
    "from utils.file_utils import open_conll_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File format must be conll or conllu\n",
    "train_data_path = \"\"\n",
    "val_data_path = \"\"\n",
    "test_data_path = \"\"\n",
    "\n",
    "# Read POS tagged data\n",
    "train_data = open_conll_file(train_data_path)\n",
    "val_data = open_conll_file(val_data_path)\n",
    "test_data = open_conll_file(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"model/indobert-large-p2-finetuned-pos\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [[word[0] for word in sentence] for sentence in train_data]\n",
    "val_sentences = [[word[0] for word in sentence] for sentence in val_data]\n",
    "test_sentences = [[word[0] for word in sentence] for sentence in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [[s[1] for s in sentence] for sentence in train_data]\n",
    "val_labels = [[s[1] for s in sentence] for sentence in val_data]\n",
    "test_labels = [[s[1] for s in sentence] for sentence in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = list(\n",
    "    set([lab for label in train_labels + val_labels + test_labels for lab in label])\n",
    ")\n",
    "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset(train_sentences, train_labels, tokenizer, MAX_LEN, labels_to_ids)\n",
    "validation_set = dataset(val_sentences, val_labels, tokenizer, MAX_LEN, labels_to_ids)\n",
    "testing_set = dataset(test_sentences, test_labels, tokenizer, MAX_LEN, labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 4\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 4\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "val_loader = DataLoader(validation_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(base_model, num_labels=len(unique_labels), id2label=ids_to_labels, label2id=labels_to_ids)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    val_loss, val_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    nb_val_examples, nb_val_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    val_preds, val_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(tqdm(training_loader)):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        tr_logits = outputs[1]\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        # if idx % 100==0:\n",
    "        #     loss_step = tr_loss/nb_tr_steps\n",
    "        #     print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_step = tr_loss/nb_tr_steps\n",
    "    \n",
    "    model.eval()\n",
    "    for idx, batch in enumerate(val_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        val_logits = outputs[1]\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        nb_val_steps += 1\n",
    "        nb_val_examples += labels.size(0)\n",
    "        \n",
    "        # if idx % 100==0:\n",
    "        #     loss_step = val_loss/nb_val_steps\n",
    "        #     print(f\"Validation loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = val_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        val_labels.extend(labels)\n",
    "        val_preds.extend(predictions)\n",
    "\n",
    "        tmp_val_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        val_accuracy += tmp_val_accuracy\n",
    "    \n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "    print(f\"Validation loss epoch: {val_loss/nb_val_steps}\")\n",
    "    print(f\"Validation accuracy epoch: {val_accuracy/nb_val_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        eval_logits = outputs[1]\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "        nb_eval_examples += labels.size(0)\n",
    "\n",
    "        # if idx % 100==0:\n",
    "        #     loss_step = eval_loss/nb_eval_steps\n",
    "        #     print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "        # compute evaluation accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "\n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "\n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        eval_labels.extend(labels)\n",
    "        eval_preds.extend(predictions)\n",
    "\n",
    "        tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [[model.config.id2label[id.item()]] for id in eval_labels]\n",
    "    predictions = [[model.config.id2label[id.item()]] for id in eval_preds]\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, predictions, digits=4))\n",
    "print(metrics.flat_classification_report(labels, predictions, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pos_tag",
   "language": "python",
   "name": "pos_tag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
